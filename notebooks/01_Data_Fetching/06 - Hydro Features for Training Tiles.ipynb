{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06 - Hydro Features for Training Tiles.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOcxuIvWgOmJPSbOjz94nfO"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.4.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"vsRaLrUSB2Q1"},"source":["# Fetching Hydrology Data\n","We have prepared shapefiles containing the USGS quarter quadrangles that have good coverage of forest stand delineations that we want to grab other data for."]},{"cell_type":"markdown","metadata":{"id":"ttEujycm1D-s"},"source":["# Mount Google Drive \n","So we can access our files showing tile locations, and save the rasters we will generate from the elevation data."]},{"cell_type":"code","metadata":{"id":"nIX843deLShB","executionInfo":{"status":"ok","timestamp":1603346836312,"user_tz":420,"elapsed":20089,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}},"outputId":"e5f55f2d-4bf0-46cf-a216-a2adc07f77bf","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4CtDxwa6ydhc","executionInfo":{"status":"ok","timestamp":1603346849306,"user_tz":420,"elapsed":9577,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}},"outputId":"ceb79aac-fee6-4b7a-c454-72be2814b5c2","colab":{"base_uri":"https://localhost:8080/","height":679}},"source":["! sudo apt-get install -y libspatialindex-dev"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  libspatialindex-c4v5 libspatialindex4v5\n","The following NEW packages will be installed:\n","  libspatialindex-c4v5 libspatialindex-dev libspatialindex4v5\n","0 upgraded, 3 newly installed, 0 to remove and 21 not upgraded.\n","Need to get 555 kB of archives.\n","After this operation, 3,308 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspatialindex4v5 amd64 1.8.5-5 [219 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspatialindex-c4v5 amd64 1.8.5-5 [51.7 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspatialindex-dev amd64 1.8.5-5 [285 kB]\n","Fetched 555 kB in 1s (702 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libspatialindex4v5:amd64.\n","(Reading database ... 144611 files and directories currently installed.)\n","Preparing to unpack .../libspatialindex4v5_1.8.5-5_amd64.deb ...\n","Unpacking libspatialindex4v5:amd64 (1.8.5-5) ...\n","Selecting previously unselected package libspatialindex-c4v5:amd64.\n","Preparing to unpack .../libspatialindex-c4v5_1.8.5-5_amd64.deb ...\n","Unpacking libspatialindex-c4v5:amd64 (1.8.5-5) ...\n","Selecting previously unselected package libspatialindex-dev:amd64.\n","Preparing to unpack .../libspatialindex-dev_1.8.5-5_amd64.deb ...\n","Unpacking libspatialindex-dev:amd64 (1.8.5-5) ...\n","Setting up libspatialindex4v5:amd64 (1.8.5-5) ...\n","Setting up libspatialindex-c4v5:amd64 (1.8.5-5) ...\n","Setting up libspatialindex-dev:amd64 (1.8.5-5) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wUsNdsi5H2sD","executionInfo":{"status":"ok","timestamp":1603346860256,"user_tz":420,"elapsed":9615,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}},"outputId":"714fa80a-7ee0-4676-d6c3-2ee6ac72b08d","colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["! pip install geopandas rtree -q"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 972kB 2.8MB/s \n","\u001b[K     |████████████████████████████████| 71kB 8.3MB/s \n","\u001b[K     |████████████████████████████████| 10.9MB 14.9MB/s \n","\u001b[K     |████████████████████████████████| 14.8MB 307kB/s \n","\u001b[?25h  Building wheel for rtree (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WhAkNSDeJR_T","executionInfo":{"status":"ok","timestamp":1603346860591,"user_tz":420,"elapsed":3846,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}}},"source":["import numpy as np\n","import geopandas as gpd\n","import os\n","import requests\n","from shapely.geometry import box, Polygon"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pc8bz1n8h4tF"},"source":["The following function will retrieve the hydro data from The National Map's web service."]},{"cell_type":"code","metadata":{"id":"dmeDTpxYzmrF","executionInfo":{"status":"ok","timestamp":1603346860593,"user_tz":420,"elapsed":419,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}}},"source":["def nhd_from_tnm(nhd_layer,\n","                 bbox,\n","                 inSR=4326,\n","                 **kwargs):\n","    \"\"\"Returns features from the National Hydrography Dataset Plus High\n","    Resolution web service from The National Map.\n","\n","    Available layers are:\n","\n","    =========  ======================\n","    NHD Layer  Description\n","    =========  ======================\n","    0          NHDPlusSink\n","    1          NHDPoint\n","    2          NetworkNHDFlowline\n","    3          NonNetworkNHDFlowline\n","    4          FlowDirection\n","    5          NHDPlusWall\n","    6          NHDPlusBurnLineEvent\n","    7          NHDLine\n","    8          NHDArea\n","    9          NHDWaterbody\n","    10         NHDPlusCatchment\n","    11         WBDHU12\n","    =========  ======================\n","\n","    Parameters\n","    ----------\n","    nhd_layer : int\n","       a value from 0-11 indicating the feature layer to retrieve.\n","    bbox : list-like\n","      list of bounding box coordinates (minx, miny, maxx, maxy).\n","    inSR : int\n","      spatial reference for bounding box, such as an EPSG code (e.g., 4326)\n","\n","    Returns\n","    -------\n","    clip_gdf : GeoDataFrame\n","      features in vector format, clipped to bbox\n","    \"\"\"\n","    BASE_URL = ''.join([\n","        'https://hydro.nationalmap.gov/arcgis/rest/services/NHDPlus_HR/',\n","        'MapServer/',\n","        str(nhd_layer), '/query?'\n","    ])\n","\n","    params = dict(where=None,\n","                  text=None,\n","                  objectIds=None,\n","                  time=None,\n","                  geometry=','.join([str(x) for x in bbox]),\n","                  geometryType='esriGeometryEnvelope',\n","                  inSR=inSR,\n","                  spatialRel='esriSpatialRelIntersects',\n","                  relationParam=None,\n","                  outFields='*',\n","                  returnGeometry='true',\n","                  returnTrueCurves='false',\n","                  maxAllowableOffset=None,\n","                  geometryPrecision=None,\n","                  outSR=inSR,\n","                  having=None,\n","                  returnIdsOnly='false',\n","                  returnCountOnly='false',\n","                  orderByFields=None,\n","                  groupByFieldsForStatistics=None,\n","                  outStatistics=None,\n","                  returnZ='false',\n","                  returnM='false',\n","                  gdbVersion=None,\n","                  historicMoment=None,\n","                  returnDistinctValues='false',\n","                  resultOffset=None,\n","                  resultRecordCount=None,\n","                  queryByDistance=None,\n","                  returnExtentOnly='false',\n","                  datumTransformation=None,\n","                  parameterValues=None,\n","                  rangeValues=None,\n","                  quantizationParameters=None,\n","                  featureEncoding='esriDefault',\n","                  f='geojson')\n","    for key, value in kwargs.items():\n","        params.update({key: value})\n","\n","    r = requests.get(BASE_URL, params=params)\n","    jsn = r.json()\n","    if len(jsn['features']) == 0:\n","        clip_gdf = gpd.GeoDataFrame(geometry=[Polygon()], crs=inSR)\n","    else:\n","        try:\n","            gdf = gpd.GeoDataFrame.from_features(jsn, crs=inSR)\n","\n","        # this API seems to return M and Z values even if not requested\n","        # this catches the error and keeps only the first two coordinates (x and y)\n","        except AssertionError:\n","            for f in jsn['features']:\n","                f['geometry'].update({\n","                    'coordinates': [c[0:2] for c in f['geometry']['coordinates']]\n","                })\n","            gdf = gpd.GeoDataFrame.from_features(jsn)\n","\n","        clip_gdf = gpd.clip(gdf, box(*bbox))\n","        if len(clip_gdf) == 0:\n","            clip_gdf = gpd.GeoDataFrame(geometry=[Polygon()], crs=inSR)\n","\n","    return clip_gdf"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NpLVIile2fjm"},"source":["# Download Data for Training Tiles"]},{"cell_type":"markdown","metadata":{"id":"nf5NAIc7jbmj"},"source":["This function will loop through a GeoDataFrame, fetch the relevant data, and write data to disk in the appropriate format."]},{"cell_type":"code","metadata":{"id":"tsG0pV4y3thH","executionInfo":{"status":"ok","timestamp":1603346864125,"user_tz":420,"elapsed":264,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}}},"source":["def fetch_hydro(gdf, state, overwrite=False):\n","    epsg = gdf.crs.to_epsg()\n","    print('Fetching hydro data for {:,d} tiles'.format(len(gdf)))\n","\n","    ## loop through all the geometries in the geodataframe\n","\n","    for idx, row in gdf.iterrows():\n","        xmin, ymin, xmax, ymax = row['geometry'].bounds\n","        xmin, ymin = np.floor((xmin, ymin))\n","        xmax, ymax = np.ceil((xmax, ymax))\n","\n","        bbox = [xmin, ymin, xmax, ymax]\n","\n","        ## don't bother fetching data if we already have processed this tile\n","        OUTROOT = '/content/drive/Shared drives/stand_mapping/data/interim/training_tiles'\n","        outfolder = f'{state.lower()}/hydro'\n","        outdir = os.path.join(OUTROOT, outfolder)\n","\n","        flow_outname = f'{row.CELL_ID}_flowlines.geojson'\n","        waterbody_outname = f'{row.CELL_ID}_waterbodies.geojson'\n","\n","        flow_outfile = os.path.join(outdir, flow_outname)     \n","        waterbody_outfile = os.path.join(outdir, waterbody_outname)  \n","\n","        if (os.path.exists(flow_outfile) and os.path.exists(waterbody_outfile)) and not overwrite:\n","            if idx % 100 == 0:\n","                print()\n","            if idx % 10 == 0:\n","                print(idx, end='')\n","            else:\n","                print('.', end='')\n","            continue\n","        \n","        flow = nhd_from_tnm(4, bbox, epsg)\n","        waterbody = nhd_from_tnm(9, bbox, epsg)\n","\n","        flow.to_file(flow_outfile, driver='GeoJSON')\n","        waterbody.to_file(waterbody_outfile, driver='GeoJSON')\n","\n","        ## report progress\n","        if idx % 100 == 0:\n","            print()\n","        if idx % 10 == 0:\n","            print(idx, end='')\n","        else:\n","            print('.', end='')"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9IOnl9mDM3fq"},"source":["## Fetch Hydro Layers for each tile"]},{"cell_type":"code","metadata":{"id":"fb8abZzEzPPi","executionInfo":{"status":"ok","timestamp":1603346874326,"user_tz":420,"elapsed":7337,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}}},"source":["SHP_DIR = '/content/drive/Shared drives/stand_mapping/data/interim'\n","\n","WA11_SHP = 'washington_utm11n_training_quads_epsg6340.shp'\n","WA10_SHP = 'washington_utm10n_training_quads_epsg6339.shp'\n","OR10_SHP = 'oregon_utm10n_training_quads_epsg6339.shp'\n","OR11_SHP = 'oregon_utm11n_training_quads_epsg6340.shp'\n","\n","or10_gdf = gpd.read_file(os.path.join(SHP_DIR, OR10_SHP))\n","or11_gdf = gpd.read_file(os.path.join(SHP_DIR, OR11_SHP))\n","wa10_gdf = gpd.read_file(os.path.join(SHP_DIR, WA10_SHP))\n","wa11_gdf = gpd.read_file(os.path.join(SHP_DIR, WA11_SHP))"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"xf4OO_-JzRkp","executionInfo":{"status":"ok","timestamp":1603346899899,"user_tz":420,"elapsed":5428,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}},"outputId":"0c3cd03c-4b37-406c-846a-47842de3b582","colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["GDF = wa11_gdf\n","STATE = 'washington'\n","\n","fetch_hydro(GDF, STATE)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Fetching hydro data for 82 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80."],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-s70rKgP8Jr1","executionInfo":{"status":"ok","timestamp":1603346904996,"user_tz":420,"elapsed":656,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}},"outputId":"07d16b1e-7450-4d37-f122-23b2502aeeaf","colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["GDF = wa10_gdf\n","STATE = 'washington'\n","\n","fetch_hydro(GDF, STATE)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Fetching hydro data for 277 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270......"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bvsuyXAi7DSa","executionInfo":{"status":"ok","timestamp":1603346927607,"user_tz":420,"elapsed":12810,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}},"outputId":"704c6510-037b-4099-ba09-bd9d366b5f07","colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["GDF = or10_gdf\n","STATE = 'oregon'\n","\n","fetch_hydro(GDF, STATE)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Fetching hydro data for 607 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........\n","300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........\n","400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........\n","500.........510.........520.........530.........540.........550.........560.........570.........580.........590.........\n","600......"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NDWrjspZ7F2L","executionInfo":{"status":"ok","timestamp":1603346932836,"user_tz":420,"elapsed":1091,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}},"outputId":"395f06e5-23bc-4fe5-de1b-1a68dd159407","colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["GDF = or11_gdf\n","STATE = 'oregon'\n","\n","fetch_hydro(GDF, STATE)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Fetching hydro data for 524 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........\n","300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........\n","400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........\n","500.........510.........520..."],"name":"stdout"}]}]}