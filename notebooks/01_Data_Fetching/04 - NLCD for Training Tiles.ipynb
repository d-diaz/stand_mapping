{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04 - NLCD for Training Tiles.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.4.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"vsRaLrUSB2Q1","colab_type":"text"},"source":["# Fetching NLCD Data\n","We have prepared shapefiles containing the USGS quarter quadrangles that have good coverage of forest stand delineations that we want to grab other data for. We'll fetch land cover classifications from the  Multiresolution Land Characteristics Consortium's web service for each tile, simplify the classification into \\{forest; field; water; or developed\\} and write our outputs as GeoTiffs to Google Drive. "]},{"cell_type":"markdown","metadata":{"id":"ttEujycm1D-s","colab_type":"text"},"source":["# Mount Google Drive \n","So we can access our files showing tile locations, and save the rasters we will generate from the elevation data."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nIX843deLShB","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600125099739,"user_tz":420,"elapsed":29822,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}},"outputId":"6e5b7de4-3e8d-4b9d-f39a-befa5aa76662"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wUsNdsi5H2sD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1600125110896,"user_tz":420,"elapsed":40965,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}},"outputId":"b086925b-3c0b-49de-ecf8-13af2f0b11a5"},"source":["! pip install geopandas rasterio -q"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 972kB 2.8MB/s \n","\u001b[K     |████████████████████████████████| 18.2MB 1.2MB/s \n","\u001b[K     |████████████████████████████████| 10.9MB 202kB/s \n","\u001b[K     |████████████████████████████████| 14.8MB 320kB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WhAkNSDeJR_T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600125111169,"user_tz":420,"elapsed":41230,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}}},"source":["import io\n","import numpy as np\n","import geopandas as gpd\n","import os\n","import rasterio\n","import requests\n","\n","from functools import partial\n","from imageio import imread\n","from matplotlib import pyplot as plt\n","from multiprocessing.pool import ThreadPool\n","from rasterio import transform"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"KOiTR0e6Zqri","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600125129542,"user_tz":420,"elapsed":59594,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}}},"source":["SHP_DIR = '/content/drive/Shared drives/stand_mapping/data/interim'\n","\n","WA11_SHP = 'washington_utm11n_training_quads_epsg6340.shp'\n","WA10_SHP = 'washington_utm10n_training_quads_epsg6339.shp'\n","OR10_SHP = 'oregon_utm10n_training_quads_epsg6339.shp'\n","OR11_SHP = 'oregon_utm11n_training_quads_epsg6340.shp'\n","\n","or10_gdf = gpd.read_file(os.path.join(SHP_DIR, OR10_SHP))\n","or11_gdf = gpd.read_file(os.path.join(SHP_DIR, OR11_SHP))\n","wa10_gdf = gpd.read_file(os.path.join(SHP_DIR, WA10_SHP))\n","wa11_gdf = gpd.read_file(os.path.join(SHP_DIR, WA11_SHP))"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pc8bz1n8h4tF","colab_type":"text"},"source":["The following functions will do the work to retrieve the NLCD raster."]},{"cell_type":"code","metadata":{"id":"70uzVqnnYknw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600125129545,"user_tz":420,"elapsed":59586,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}}},"source":["def nlcd_from_mrlc(bbox, res, layer, inSR=4326, nlcd=True, **kwargs):\n","    \"\"\"\n","    Retrieves National Land Cover Data (NLCD) Layers from the Multiresolution\n","    Land Characteristics Consortium's web service.\n","\n","    Parameters\n","    ----------\n","    bbox : list-like\n","      list of bounding box coordinates (minx, miny, maxx, maxy)\n","    res : numeric\n","      spatial resolution to use for returned raster (grid cell size)\n","    layer : str\n","      title of layer to retrieve (e.g., 'NLCD_2001_Land_Cover_L48')\n","    inSR : int\n","      spatial reference for bounding box, such as an EPSG code (e.g., 4326)\n","    nlcd : bool\n","      if True, will re-map the values returned to the NLCD land cover codes\n","\n","    Returns\n","    -------\n","    img : numpy array\n","      map image as array\n","    \"\"\"\n","    width = int(abs(bbox[2] - bbox[0]) // res)\n","    height = int(abs(bbox[3] - bbox[1]) // res)\n","    BASE_URL = ''.join([\n","        'https://www.mrlc.gov/geoserver/mrlc_display/wms?',\n","        'service=WMS&request=GetMap',\n","    ])\n","\n","    params = dict(bbox=','.join([str(x) for x in bbox]),\n","                  crs=f'epsg:{inSR}',\n","                  width=width,\n","                  height=height,\n","                  format='image/tiff',\n","                  layers=layer)\n","    for key, value in kwargs.items():\n","        params.update({key: value})\n","\n","    r = requests.get(BASE_URL, params=params)\n","    img = imread(io.BytesIO(r.content), format='tiff')\n","\n","    if nlcd:\n","        MAPPING = {\n","            1: 11,  # open water\n","            2: 12,  # perennial ice/snow\n","            3: 21,  # developed, open space\n","            4: 22,  # developed, low intensity\n","            5: 23,  # developed, medium intensity\n","            6: 24,  # developed, high intensity\n","            7: 31,  # barren land (rock/stand/clay)\n","            8: 32,  # unconsolidated shore\n","            9: 41,  # deciduous forest\n","            10: 42,  # evergreen forest\n","            11: 43,  # mixed forest\n","            12: 51,  # dwarf scrub (AK only)\n","            13: 52,  # shrub/scrub\n","            14: 71,  # grasslands/herbaceous,\n","            15: 72,  # sedge/herbaceous (AK only)\n","            16: 73,  # lichens (AK only)\n","            17: 74,  # moss (AK only)\n","            18: 81,  # pasture/hay\n","            19: 82,  # cultivated crops\n","            20: 90,  # woody wetlands\n","            21: 95,  # emergent herbaceous wetlands\n","        }\n","\n","        k = np.array(list(MAPPING.keys()))\n","        v = np.array(list(MAPPING.values()))\n","\n","        mapping_ar = np.zeros(k.max() + 1, dtype=v.dtype)\n","        mapping_ar[k] = v\n","        img = mapping_ar[img]\n","\n","    return img\n","\n","def quad_fetch(fetcher, bbox, num_threads=4, qq=False, *args, **kwargs):\n","    \"\"\"Breaks user-provided bounding box into quadrants and retrieves data\n","    using `fetcher` for each quadrant in parallel using a ThreadPool.\n","\n","    Parameters\n","    ----------\n","    fetcher : callable\n","      data-fetching function, expected to return an array-like object\n","    bbox : 4-tuple or list\n","      coordinates of x_min, y_min, x_max, and y_max for bounding box of tile\n","    num_threads : int\n","      number of threads to use for parallel executing of data requests\n","    qq : bool\n","      whether or not to execute request for quarter quads, which executes this\n","      function recursively for each quadrant\n","    *args\n","      additional positional arguments that will be passed to `fetcher`\n","    **kwargs\n","      additional keyword arguments that will be passed to `fetcher`\n","\n","    Returns\n","    -------\n","    quad_img : array\n","      image returned with quads stitched together into a single array\n","\n","    \"\"\"\n","    bboxes = split_quad(bbox)\n","\n","    if qq:\n","        nw = quad_fetch(fetcher, bbox=bboxes[0], *args, **kwargs)\n","        ne = quad_fetch(fetcher, bbox=bboxes[1], *args, **kwargs)\n","        sw = quad_fetch(fetcher, bbox=bboxes[2], *args, **kwargs)\n","        se = quad_fetch(fetcher, bbox=bboxes[3], *args, **kwargs)\n","\n","    else:\n","        get_quads = partial(fetcher, *args, **kwargs)\n","        with ThreadPool(num_threads) as p:\n","            quads = p.map(get_quads, bboxes)\n","            nw, ne, sw, se = quads\n","\n","    quad_img = np.vstack([np.hstack([nw, ne]), np.hstack([sw, se])])\n","\n","    return quad_img\n","\n","def split_quad(bbox):\n","    xmin, ymin, xmax, ymax = bbox\n","    nw_bbox = [xmin, (ymin + ymax) / 2, (xmin + xmax) / 2, ymax]\n","    ne_bbox = [(xmin + xmax) / 2, (ymin + ymax) / 2, xmax, ymax]\n","    sw_bbox = [xmin, ymin, (xmin + xmax) / 2, (ymin + ymax) / 2]\n","    se_bbox = [(xmin + xmax) / 2, ymin, xmax, (ymin + ymax) / 2]\n","\n","    return [nw_bbox, ne_bbox, sw_bbox, se_bbox]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-VwTHYn5vvH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600125129546,"user_tz":420,"elapsed":59579,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}}},"source":["LOOKUP_LAYER_BY_YEAR = {2009: 'NLCD_2008_Land_Cover_L48',\n","                        2011: 'NLCD_2011_Land_Cover_L48', \n","                        2012: 'NLCD_2011_Land_Cover_L48', \n","                        2013: 'NLCD_2013_Land_Cover_L48',\n","                        2014: 'NLCD_2013_Land_Cover_L48', \n","                        2015: 'NLCD_2013_Land_Cover_L48', \n","                        2016: 'NLCD_2016_Land_Cover_L48',\n","                        2017: 'NLCD_2016_Land_Cover_L48',\n","}"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NpLVIile2fjm","colab_type":"text"},"source":["# Download Data for Training Tiles\n","Here is where are shapefiles of USGS Quarter Quads live:\n"]},{"cell_type":"markdown","metadata":{"id":"nf5NAIc7jbmj","colab_type":"text"},"source":["These functions will loop through a GeoDataFrame, fetch the relevant data, and write GeoTiffs to disk in the appropriate formats."]},{"cell_type":"code","metadata":{"id":"tsG0pV4y3thH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600125129546,"user_tz":420,"elapsed":59570,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}}},"source":["def fetch_nlcd(gdf, state, year, overwrite=False):\n","    epsg = gdf.crs.to_epsg()\n","    print('Fetching NLCD data for {:,d} tiles'.format(len(gdf)))\n","    \n","    PROFILE = {\n","        'driver': 'GTiff',\n","        'interleave': 'band',\n","        'tiled': True,\n","        'blockxsize': 256,\n","        'blockysize': 256,\n","        'compress': 'lzw',\n","        'nodata': 0,\n","        'dtype': rasterio.uint8,\n","        'count': 1,\n","        }\n","\n","    ## loop through all the geometries in the geodataframe and fetch NLCD data\n","\n","    for idx, row in gdf.iterrows():\n","        xmin, ymin, xmax, ymax = row['geometry'].bounds\n","        xmin, ymin = np.floor((xmin, ymin))\n","        xmax, ymax = np.ceil((xmax, ymax))\n","\n","        width, height = xmax-xmin, ymax-ymin\n","        trf = transform.from_bounds(xmin, ymin, xmax, ymax, width, height)\n","\n","        ## don't bother fetching data if we already have processed this tile\n","        if state.lower() == 'or':\n","            state_name = 'oregon'\n","        elif state.lower() == 'wa':\n","            state_name = 'washington'\n","        outdir = f'/content/drive/Shared drives/stand_mapping/data/interim/training_tiles/{state_name}/nlcd/{year}'\n","        outname = f'{row.CELL_ID}_nlcd_{year}.tif'\n","        outfile = os.path.join(outdir, outname)        \n","        if os.path.exists(outfile) and not overwrite:\n","            if idx % 100 == 0:\n","                print()\n","            if idx % 10 == 0:\n","                print(idx, end='')\n","            else:\n","                print('.', end='')\n","            continue\n","        \n","        layer = LOOKUP_LAYER_BY_YEAR[year] # nlcd layer to fetch\n","        try:\n","            nlcd = quad_fetch(nlcd_from_mrlc, \n","                            bbox=[xmin, ymin, xmax, ymax], \n","                            res=1, inSR=epsg, noData=0, layer=layer)\n","        except:\n","            print('x', end='')\n","            continue\n","        \n","        ## write the data to disk\n","        PROFILE.update(width=width, height=height)\n","\n","        with rasterio.open(outfile, 'w', \n","                           **PROFILE, crs=epsg, transform=trf) as dst:\n","            dst.write(nlcd.astype(rasterio.uint8), 1)\n","            dst.set_band_description(1, 'NLCD retrieved from MRLCC')\n","        \n","        ## report progress\n","        if idx % 100 == 0:\n","            print()\n","        if idx % 10 == 0:\n","            print(idx, end='')\n","        else:\n","            print('.', end='')\n","    print()"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9IOnl9mDM3fq","colab_type":"text"},"source":["## Fetch NLCD layer for each tile in each year"]},{"cell_type":"code","metadata":{"id":"R0-QXtsyMTXq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":797},"executionInfo":{"status":"ok","timestamp":1600128031591,"user_tz":420,"elapsed":2961598,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}},"outputId":"47f1df04-ffd3-4ee2-8800-ca203e6e4eec"},"source":["GDF = or11_gdf\n","STATE = 'OR'\n","YEARS = [2009, 2011, 2012, 2014, 2016]\n","\n","for year in YEARS:\n","    print(year)\n","    fetch_nlcd(GDF, 'OR', year)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["2009\n","Fetching NLCD data for 524 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........\n","300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........\n","400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........\n","500.........510.........520...\n","2011\n","Fetching NLCD data for 524 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........\n","300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........\n","400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........\n","500.........510.........520...\n","2012\n","Fetching NLCD data for 524 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........\n","300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........\n","400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........\n","500.........510.........520...\n","2014\n","Fetching NLCD data for 524 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........\n","300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........\n","400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........\n","500.........510.........520...\n","2016\n","Fetching NLCD data for 524 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........\n","300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........\n","400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........\n","500.........510.........520...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jEw7swEyboLY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":884},"executionInfo":{"status":"ok","timestamp":1600132391733,"user_tz":420,"elapsed":7321732,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}},"outputId":"0793b22d-70fc-4a54-eea6-58f3e25d91b0"},"source":["GDF = or10_gdf\n","STATE = 'OR'\n","YEARS = [2009, 2011, 2012, 2014, 2016]\n","\n","for year in YEARS:\n","    print(year)\n","    fetch_nlcd(GDF, STATE, year)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["2009\n","Fetching NLCD data for 607 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........\n","300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........\n","400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........\n","500.........510.........520.........530.........540.........550.........560.........570.........580.........590.......x.\n","600......\n","2011\n","Fetching NLCD data for 607 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........\n","300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........\n","400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........\n","500.........510.........520.........530.........540.........550.........560.........570.........580.........590.........\n","600......\n","2012\n","Fetching NLCD data for 607 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........\n","300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........\n","400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........\n","500.........510.........520.........530.........540.........550.........560.........570.........580.........590.........\n","600......\n","2014\n","Fetching NLCD data for 607 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........\n","300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........\n","400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........\n","500.........510.........520.........530.........540.........550.........560.........570.........580.........590.........\n","600......\n","2016\n","Fetching NLCD data for 607 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........\n","300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........\n","400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........\n","500.........510.........520.........530.........540.........550.........560.........570.........580.........590.........\n","600......\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Cw3r5JmQZjU4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":364},"executionInfo":{"status":"ok","timestamp":1600132407644,"user_tz":420,"elapsed":7337635,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}},"outputId":"0e49be1b-ca9b-454b-90a0-d78fc6f934ba"},"source":["GDF = wa11_gdf\n","STATE = 'WA'\n","YEARS = [2009, 2011, 2013, 2015, 2017]\n","\n","for year in YEARS:\n","    print(year)\n","    fetch_nlcd(GDF, STATE, year)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["2009\n","Fetching NLCD data for 82 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.\n","2011\n","Fetching NLCD data for 82 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.\n","2013\n","Fetching NLCD data for 82 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.\n","2015\n","Fetching NLCD data for 82 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.\n","2017\n","Fetching NLCD data for 82 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q8nf2fICb9jO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":537},"executionInfo":{"status":"ok","timestamp":1600132409069,"user_tz":420,"elapsed":7339051,"user":{"displayName":"David Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjh1OmCKzplbVp1ZPZLYNeFVoDha8mOgjOpP5ISnQ=s64","userId":"05894085007010941086"}},"outputId":"5dda647e-b8b6-4163-d265-08f7bde5af6f"},"source":["GDF = wa10_gdf\n","STATE = 'WA'\n","YEARS = [2009, 2011, 2013, 2015, 2017]\n","\n","for year in YEARS:\n","    print(year)\n","    fetch_nlcd(GDF, STATE, year)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["2009\n","Fetching NLCD data for 277 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270......\n","2011\n","Fetching NLCD data for 277 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270......\n","2013\n","Fetching NLCD data for 277 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270......\n","2015\n","Fetching NLCD data for 277 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270......\n","2017\n","Fetching NLCD data for 277 tiles\n","\n","0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........\n","100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........\n","200.........210.........220.........230.........240.........250.........260.........270......\n"],"name":"stdout"}]}]}